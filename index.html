<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Foundation Model-Driven Grasping of Unknown Objects via Center of Gravity Estimation">
  <meta name="keywords" content="Robotic Grasping, Center of Gravity, Foundation Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Foundation Model-Driven Grasping of Unknown Objects via Center of Gravity Estimation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* 视频容器样式调整 - 两行两列布局 */
    .video-section {
      max-width: 1000px;
      margin: 0 auto;
      padding: 0 1rem;
    }
    
    .video-group {
      margin-bottom: 3rem;
    }
    
    .video-group-title {
      text-align: center;
      margin: 2rem 0 2rem;
      font-size: 1.2rem;
      font-weight: bold;
      color: #333;
    }
    
    .video-row {
      display: flex;
      justify-content: center;
      gap: 3rem; /* 增加间距使布局更匀称 */
      margin-bottom: 2.5rem;
      flex-wrap: wrap;
    }
    
    /* 两行两列布局 - 每个视频项宽度适中 */
    .video-item {
      width: 280px; /* 适度增大视频宽度 */
      flex-shrink: 0;
    }
    
    .video-container {
      position: relative;
      width: 100%;
      height: 157px; /* 保持16:9比例 */
      overflow: hidden;
      border-radius: 6px;
      background-color: #f0f0f0;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }
    
    .video-container video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: contain;
    }
    
    .video-caption {
      text-align: center;
      margin-top: 0.8rem;
      font-size: 0.95rem;
      color: #333;
      min-height: 24px;
    }
    
    /* 响应式调整 */
    @media (max-width: 800px) {
      .video-item {
        width: 220px;
      }
      .video-container {
        height: 124px;
      }
      .video-row {
        gap: 2rem;
      }
    }
    
    @media (max-width: 550px) {
      .video-item {
        width: 100%;
        max-width: 300px;
      }
      .video-container {
        height: 169px;
      }
      .video-row {
        gap: 1.5rem;
        margin-bottom: 1.5rem;
      }
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Foundation Model-Driven Grasping of Unknown Objects via Center of Gravity Estimation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Kang Xiangli</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Yage He</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Xianwu Gong<sup>*</sup></a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="#">Zhan Liu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="#">Yuru Bai</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Electronics and Control Engineering, Chang'an University, Xi'an, Shaanxi, China</span><br>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block">Email: kxiangli@chd.edu.cn, heyage@chd.edu.cn, xwgong@chd.edu.cn, chdlzh@chd.edu.cn, baiyuru@chd.edu.cn</span>
            <p class="is-size-6" style="margin-top: 0.3rem; font-style: italic;">* Corresponding author</p>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- 可在此处添加论文链接（如PDF、代码等） -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This study presents a grasping method for objects with uneven mass distribution by leveraging diffusion models to localize the center of gravity (CoG) on unknown objects. In robotic grasping, CoG deviation often leads to postural instability, where existing keypoint-based or affordance-driven methods exhibit limitations. We constructed a dataset of 790 images featuring unevenly distributed objects with keypoint annotations for CoG localization. A vision-driven framework based on foundation models was developed to achieve CoG-aware grasping. Experimental evaluations across real-world scenarios demonstrate that our method achieves a 49\% higher success rate compared to conventional keypoint-based approaches and an 11\% improvement over state-of-the-art affordance-driven methods. The system exhibits strong generalization with a 76\% CoG localization accuracy on unseen objects.This provides an innovative solution for precise and stable grasping tasks, with its scientific validity further validated in complex and dynamic scenarios.
          </p>
        </div>
      </div>
    </div>
    
    <!-- Overview -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="publication-image">
          <img src="static/images/框图.png" alt="系统框图" style="max-width:100%;height:auto;">
          <div style="margin-top:8px; font-size:0.9rem; color:#666; text-align:center;">
            <p>
              <strong>Left:</strong> Given the instruction and current RGB-D images, the VLM first identifies the target object. It then generalizes the segmented image and maps the center of gravity to the current scene using the center-of-gravity module, selecting the nearest and highest-scoring grasp pose. 
              <strong>Right:</strong> The image on the right shows the captured result in a real-world scenario, depicting the grasped objects: a rasp, crowbar, pliers, and ratchet wrench. The method described in this paper enables grasping of unseen objects without requiring additional training.
            </p>
          </div>
        </div>
      </div>
    </div>
    
    <!-- Real World Experiments -->
    <div class="columns is-centered has-text-centered video-section">
      <div class="column is-four-fifths">
        <h2 class="title is-3">In the real world</h2>
        <p style ="text-align: left;">
          In the real world, we conducted experiments using the Piper robotic arm, with point cloud data acquired via the D435 scanner. We compiled an image dataset comprising 790 centre-of-gravity points. The dataset includes common household objects such as hammers, hand files, ratchet wrenches, screwdrivers, and pincers. We tested ten objects with uneven mass distributions in real-world settings, evaluating the model's performance in both complex and dynamic scenarios.
        </p>
        
        <!-- 第一组视频（复杂环境）- 两行两列布局 -->
        <div class="video-group">
          <div class="video-group-title">Tool Grasping in Complex Environments</div>
          
          <!-- 第一行两个视频：扳手、锤子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/扳手.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Wrench</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/锤子.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Hammer</div>
            </div>
          </div>
          
          <!-- 第二行两个视频：搓刀、钳子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/搓刀.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">File</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/钳子.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Pliers</div>
            </div>
          </div>
        </div>

        <!-- 第二组视频（闭环条件）- 两行两列布局 -->
        <div class="video-group">
          <div class="video-group-title">Tool Grasping under Closed-Loop Conditions</div>
          
          <!-- 第一行两个视频：扳手、锤子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/扳手_动态.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Wrench</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/锤子_动态.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Hammer</div>
            </div>
          </div>
          
          <!-- 第二行两个视频：搓刀、钳子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/搓刀_动态.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">File</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/钳子_动态.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Pliers</div>
            </div>
          </div>
        </div>

        <!-- 第三组视频（复杂环境False）- 两行两列布局 -->
        <div class="video-group">
          <div class="video-group-title">Tool Grasping in Complex Environments（False）</div>
          
          <!-- 第一行两个视频：扳手、锤子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/扳手F.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Wrench</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/锤子F.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Hammer</div>
            </div>
          </div>
          
          <!-- 第二行两个视频：搓刀、钳子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/搓刀F.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">File</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/钳子F.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Pliers</div>
            </div>
          </div>
        </div>

        <!-- 第四组视频（闭环条件False）- 两行两列布局 -->
        <div class="video-group">
          <div class="video-group-title">Tool Grasping under Closed-Loop Conditions（False）</div>
          
          <!-- 第一行两个视频：扳手、锤子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <!-- 修正：移除路径中的多余空格，保持与其他视频命名格式一致 -->
                <video controls loop autoplay>
                  <source src="static/videos/扳手1.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Wrench</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/锤子_动态F.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Hammer</div>
            </div>
          </div>
          
          <!-- 第二行两个视频：搓刀、钳子 -->
          <div class="video-row">
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/搓刀_动态F.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">File</div>
            </div>
            <div class="video-item">
              <div class="video-container">
                <video controls loop autoplay>
                  <source src="static/videos/钳子_动态F.mp4" type="video/mp4">
                </video>
              </div>
              <div class="video-caption">Pliers</div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

</body>
</html>
